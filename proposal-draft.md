## Project Overview
- **Objective**: Fine-tune a GPT model for a chatbox simulating a targeted person's style with background input.
- **Base Model**: GPT-3.5.
- **Finetuning Technique**: [LoRA/Soft-Prompting/Other].

## Participants
- **Name1**: SID1
- **Name2**: SID2
- **Name3**: SID3
- **Name4**: SID4

## High-Level Task Description
_Describe the task in 1-2 sentences._

## Data and Resources
- **Datasets**: Self-composed
- **Compute**: tenth of minutes
- **Storage**: Enough

## Milestones
- **Week 1**: Figure out the API of GPT fine tuning.
- **Week 2**: Compose designed datasets for fine tuning.
- **Week 3**: Analyze results and compare effects in different periods within fine tuning.
- **Week 4**: Summary and report.

## Expected Deliverables
- Fine-tuned model
- Generated text samples
- Performance analysis report
- Training / Testing loss curve


## References
-
-

## GitHub Repo
https://github.com/jimchen2/CS182-Final-Project
